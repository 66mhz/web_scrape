{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d36fc2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d6a007",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://ntbg.org/database/plants/detail/hibiscus-kokio-ssp-saintjohnianus\")\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "#print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd63c521",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "page = requests.get(\"https://ntbg.org/database/plants/search\")\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "#print(soup)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861c4ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = soup.find_all('div', {'class':'searchresult-item'})\n",
    "print(job)\n",
    "# print(job.find_all('a')[0])\n",
    "# for link in job.find_all('a'):\n",
    "#     print(link.get('href'))\n",
    "# for link in job.find_all('img'):\n",
    "#     print(link.get('data-title'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb914d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#per city HTML file is fed and list of plants we get.\n",
    "cities = ['hawaii','cuba','panama','florida','costa_rica','samoa','tonga','fiji','guam']\n",
    "translate_table = str.maketrans({' ': '_'})\n",
    "translate_table_raw = str.maketrans({' ': '-'})\n",
    "plant_names = []\n",
    "plant_names_raw = []\n",
    "for city in cities:\n",
    "    with open(\"/home/cg/cagristuff/web_scrape/%s.html\"%city) as fp:\n",
    "        city = BeautifulSoup(fp, 'html.parser')\n",
    "        plants_name = city.find_all('div', {'class':'searchresult-item'})\n",
    "        #print(plants_name)\n",
    "        for link in plants_name:\n",
    "            name = link.find('a').find('img').get('alt')\n",
    "            plant_names_raw.append(name.translate(translate_table_raw))\n",
    "            name = name.translate(translate_table)\n",
    "            while(name[-1] == '_'):\n",
    "                name = name[:-2]\n",
    "            #print(name)\n",
    "            plant_names.append(name)\n",
    "            \n",
    "with open('/home/cg/cagristuff/web_scrape/plant_names.csv', 'w', newline=\"\") as myfile:\n",
    "    wr = csv.writer(myfile)\n",
    "    wr.writerow(plant_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c1453e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IMAGE_WORK_DIR = '/home/cg/cagristuff/web_scrape/images/'\n",
    "for plant in plant_names_raw:\n",
    "    while((plant[-1] == '-') | (plant[-1] == '2') | (plant[-1] == '%')):\n",
    "        plant = plant[:-2]\n",
    "    print(plant)\n",
    "    #continue\n",
    "    page = requests.get(\"https://ntbg.org/database/plants/detail/%s\"%plant)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    job = soup.find('div', {'id':'slides'})\n",
    "    path = os.path.join(IMAGE_WORK_DIR, plant)\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    os.chdir(path)\n",
    "    for link in job.find_all('a'):\n",
    "        print(link.get('href'))\n",
    "        !curl {link.get('href')} --output {str(link.get('href')).split('/')[-1]}\n",
    "    os.chdir(f'{path}/../')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6bf3a9",
   "metadata": {},
   "source": [
    "# Google Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28b90f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.google.com/search?q=abutilon+menziesii&tbm=isch&source=hp&biw=1562&bih=887&ei=cddRYvHxKNKBqtsPpNuLsAs&iflsig=AHkkrS4AAAAAYlHlgWKQ1YvaoZTcmElVGdiO9lJwTD_H&ved=0ahUKEwix7qjt1If3AhXSgGoFHaTtArYQ4dUDCAc&uact=5&oq=abutilon+menziesii&gs_lcp=CgNpbWcQAzIFCAAQgARQ1C9Y1C9gkjNoAHAAeACAATmIATmSAQExmAEAoAECoAEBqgELZ3dzLXdpei1pbWewAQA&sclient=img\"\n",
    "\n",
    "page = requests.get(url)\n",
    "page_parsed = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "job = page_parsed.find_all('a')\n",
    "#for link in job.find('href'):\n",
    "#    print(link)\n",
    "#print(len(job))\n",
    "# for item in job:\n",
    "#     if '.jpg' in str(item):\n",
    "#         print(item)\n",
    "# #print(job)\n",
    "\n",
    "job2 = page_parsed.find_all('img', 'src')\n",
    "for item in job2:\n",
    "    print(item)\n",
    "#print(job2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baa15a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
